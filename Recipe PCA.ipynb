{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipes PCA\n",
    "### By Brian Kitano\n",
    "\n",
    "Okay, I'm going to use the Epicurious dataset to identify palates common across their recipes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction / Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure\n",
    "1. Download the JSON data\n",
    "2. Parse the JSON to extract recipe names and ingredients with their quantities.\n",
    "3. Create the data matrix M, where each column is a recipe and each row is an ingredient; the entry is the quantity in a normalized and standardized quantity (grams?)\n",
    "4. PCA\n",
    "\n",
    "Bonus: construct the bipartite graph of ingredients to recipes, and then project it down onto a unipartite graph of ingredients where the weight of each edge is the frequency of connections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Parse the ingredients to extract recipe names and ingredients with their quantities\n",
    "import json\n",
    "\n",
    "# load in the epicurious set\n",
    "with open('full_format_recipes.json') as f:\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    \n",
    "# print data[0]['ingredients']\n",
    "# len(data) = 20130\n",
    "\n",
    "# need to filter out the recipes that don't have ingredients listed\n",
    "# extractIngredients = lambda i: data[i].keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199315\n",
      "83465\n"
     ]
    }
   ],
   "source": [
    "def containsIngredients(index):\n",
    "    if 'ingredients' in data[i].keys():\n",
    "        return i\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# get all of the indices which contain ingredients\n",
    "cleanedIndices = [ containsIngredients(i) for i in range(len(data)) ]\n",
    "\n",
    "# get all of the ingredient lists as a list of lists\n",
    "cleanedIngredientsLists = [ data[i]['ingredients'] for i in cleanedIndices ]\n",
    "\n",
    "# flatten this list, which might contain duplicates\n",
    "cleanedIngredients = [ ingredient for ingredientList in cleanedIngredientsLists for ingredient in ingredientList]\n",
    "print len(cleanedIngredients)\n",
    "\n",
    "# remove any duplicates\n",
    "uniqueCleanedIngredients = list(set(cleanedIngredients))\n",
    "print len(uniqueCleanedIngredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "Before we write all of the ingredients to a file, we should do some NLP cleaning. In looking at the results of the first model run, it seems like to be conservative we should remove all the text that occurs in parentheses, as this seems to really mess up the CRF's ability to identify units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove things in parentheses (use regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83465\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# remove all the text that is inside a parenthesis\n",
    "noParenthesisIngredients = [re.sub(r'\\([^)]*\\)', '', ingredient) for ingredient in uniqueCleanedIngredients]\n",
    "\n",
    "print len(noParenthesisIngredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dealing with the word \"plus\"\n",
    "\n",
    "More complex problem. There are lots of ways that \"plus\" is used. Some examples:\n",
    "\n",
    "##### when quantities don't add nicely\n",
    "- \"1/2 cup plus 1 1/2 tablespoons red wine vinegar\"\n",
    "- \"1/2 cup plus 2 tablespoons granola\"\n",
    "- \"1/4 cup plus 1 tablespoon warm water\"\n",
    "- \"1/4 teaspoon plus 1/3 cup sugar\"\n",
    "- \"2 tablespoons plus 1/2 cup chopped fresh dill\"\n",
    "- \"1 tablespoon plus 1/2 teaspoon Dijon mustard\"\n",
    "- \"2/3 cup plus 6 tablespoons coarsely chopped pecans\"\n",
    "- \"1 cup plus 2 tablespoons whole milk\"\n",
    "- \"1 1/2 cups plus 2 tablespoons sugar\"\n",
    "- \"1 1/2 cups plus 2 tablespoons water\"\n",
    "- \"1 tablespoon plus 3/4 teaspoon ground cinnamon\"\n",
    "- \"1 tablespoon plus one teaspoon fresh lemon juice\"\n",
    "\n",
    "These are in a consistent format of UNIT QUANTITY PLUS UNIT QUANTITY INGREDIENT. If we add PLUS as a label, then over the 3k samples we have we might improve, but we might also tag some things as being PLUS when we don't want them to be.\n",
    "\n",
    "##### when there's a suggestion for more on the side (not a lot of errors there)\n",
    "- \"1/4 cup olive oil, plus more for grilling\"\n",
    "- \"5 teaspoons all-purpose flour plus more for dusting\"\n",
    "- \"2 tablespoons drained capers plus more for serving\"\n",
    "- \"1/2 cup freshly grated Parmesan cheese plus additional for passing\"\n",
    "- \"12 rice-paper rounds, plus more in case some tear\"\n",
    "- \"1 can whole tomatoes, plus juice\"\n",
    "- \"1 tablespoon chile oil containing sesame oil plus some of sediment from jar\"\n",
    "\n",
    "These ones seem like i can just remove all the words after the plus.\n",
    "\n",
    "##### other, stupid ones\n",
    "- \"8 cornichons, finely chopped, plus 2 pickled onions from the jar, minced\"\n",
    "- \"1/2 cup oil-packed sun-dried tomatoes, chopped, plus 2 tablespoons tomato oil\"\n",
    "- \"1 tablespoon fresh rosemary leaves or 1 teaspoon crumbled dried, plus rosemary sprigs for garnish\"\n",
    "- \"Juice of 1/4 lime, plus 1 lime wedge for garnish\"\n",
    "- \"1 1/2 cups sugar, plus 1/4 cup mixed with 1 tablespoon cinnamon, on a plate\"\n",
    "- \"1/2 fennel bulb, finely chopped, plus 1 tablespoon finely chopped fronds\"\n",
    "- \"1/4 cup chopped fresh cilantro plus 32 whole fresh cilantro leaves\"\n",
    "- \"6 large celery stalks, thickly sliced, plus 2 1/2 cups 1/2-inch-thick slices\"\n",
    "- \"6 fresh mint leaves plus 1 mint sprig for garnish\"\n",
    "\n",
    "So also there's like a utility function that might need to be taken into account: we really want our data to fit the format nicely of having a name, a unit, and a quantity. \n",
    "\n",
    "A really, really easy way to deal with all of this is just to get rid of all the \"plus\" ingredient listings, which are only ~3000 out of the 83k samples. It might mess up the data but it's easier. Also none of this is training or testing data, this is like actually \"I need this\" data so it's convenient if I just scrap the shitty stuff. It will also probably have come up in other sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80480"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use a regex to tag an igredient any time \"plus\" appears as a word with or without a comma on its own\n",
    "noPlusListings = list(filter(lambda ingredient: (re.search(\"\\s*(plus)\\,*\\s*\", ingredient) == None), noParenthesisIngredients))\n",
    "\n",
    "len(noPlusListings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dashes, commas, and other grammar thingies\n",
    "might be worth removing all of that, but not going to yet. \n",
    "\n",
    "##### Asterisks (*)\n",
    "Asterisks appear in two variants:\n",
    "\"2 1/2 pounds Jerusalem artichokes *\" where the asterisk is at the end, and \"*seedless red grapes\" where it's indicating that this is the start of a comment. We can thus remove anything after an asterisk, since it doesn't matter in either case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all the text after an asterisk\n",
    "asteriskFreeListings = [ re.sub(\"\\*.*\\n*\",'',ingredient) for ingredient in noPlusListings ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"a\" and \"an\"\n",
    "This probably maps to the number 1 right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### typos\n",
    "\n",
    "like fam what how is that even ugh how do i check for typos here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"or\"\n",
    "we could remove all the tokens after the word \"or\", since it's optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the things after an or\n",
    "noOrListings = [ re.sub(\"[^A-z]\\.*\\,*\\s*(or|OR|Or)+.*\",'', ingredient) for ingredient in asteriskFreeListings ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's write this clean stuff to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the ingredients to a file, which we'll then feed to a model\n",
    "with open('ingredientsList.txt', 'a') as the_file:\n",
    "    for ingredient in noOrListings:\n",
    "        if ingredient != \"\":\n",
    "            asciiOnlyIngredient = \"\".join(i for i in ingredient if ord(i)<128)\n",
    "            ingredientString = asciiOnlyIngredient + \"\\n\"\n",
    "            the_file.write(ingredientString)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemon juice\n",
      "cup\n",
      "1 1/4\n"
     ]
    }
   ],
   "source": [
    "# okay, the model ran and i've got the sauce\n",
    "\n",
    "# load in the labeled stuff\n",
    "with open('results.json') as g:\n",
    "    labeledIngredients = json.load(g)\n",
    "    g.close()\n",
    "    \n",
    "print labeledIngredients[0]['name']\n",
    "print labeledIngredients[0]['unit']\n",
    "print labeledIngredients[0]['qty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "# now we need to normalize all of the units and measures. We'll use milliliters for volume and grams for mass.\n",
    "\n",
    "# first we'll get a list of all the units\n",
    "def containsUnit(i):\n",
    "    if 'unit' in labeledIngredients[i].keys():\n",
    "        return i\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# get all of the indices which contain units\n",
    "unitContainingIndices = [containsUnit(i) for i in range(len(labeledIngredients))]\n",
    "unitContainingIndices = list(set(unitContainingIndices))\n",
    "\n",
    "# get all of the units\n",
    "unitList = [labeledIngredients[i]['unit'] for i in list(set(unitContainingIndices))]\n",
    "\n",
    "# remove duplicates\n",
    "uniqueUnitList = list(set(unitList))\n",
    "\n",
    "print len(uniqueUnitList) # 764 bruh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre and Post Modeling Cleaning\n",
    "What cleaning should be done before we feed the model, and what cleaning should be done after? Also, should we change our factor functions? \n",
    "\n",
    "Well, let's think quantitatively about what cleaning means now. We've identified the units from the model, and they're obviously not perfect. We should look at whether we can just cut the shitty ones out now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12-ounce bottle: 5\n",
      "branch: 5\n",
      "fifth: 5\n",
      "pair: 5\n",
      "pinch sprig: 5\n",
      "stem: 5\n",
      "12-ounce bag: 6\n",
      "12-ounce bunch: 6\n",
      "cup piece: 6\n",
      "cup stalk: 6\n",
      "cup strip: 6\n",
      "cup tablespoon cup: 6\n",
      "link: 6\n",
      "ounce bunch: 6\n",
      "ounce can: 6\n",
      "ounce cup: 6\n",
      "packet: 6\n",
      "piece fillet: 6\n",
      "pound ounce: 6\n",
      "pound slice: 6\n",
      "pound stalk: 6\n",
      "segment: 6\n",
      "tablespoon stalk: 6\n",
      "tablespoon teaspoon: 6\n",
      "bulb tablespoon: 7\n",
      "bunch sprig: 7\n",
      "clove clove: 7\n",
      "cup cup: 7\n",
      "cup teaspoon: 7\n",
      "head clove: 7\n",
      "ounce fillet: 7\n",
      "pound cup: 7\n",
      "pound pound: 7\n",
      "tablespoon cup: 7\n",
      "tablespoon sprig: 7\n",
      "can fillet: 8\n",
      "cup slice: 8\n",
      "drop: 8\n",
      "tablespoon tablespoon: 8\n",
      "teaspoon teaspoon: 8\n",
      "twist: 8\n",
      "12-ounce: 9\n",
      "chunk: 9\n",
      "log: 9\n",
      "splash: 9\n",
      "liter: 10\n",
      "ball: 11\n",
      "cup tablespoon: 11\n",
      "ounce slice: 12\n",
      "pound fillet: 12\n",
      "square: 12\n",
      "wedge: 12\n",
      "knob: 13\n",
      "rack: 13\n",
      "batch: 14\n",
      "clove teaspoon: 15\n",
      "gallon: 15\n",
      "cube: 17\n",
      "box: 23\n",
      "cup sprig: 27\n",
      "sheet: 28\n",
      "envelope: 29\n",
      "bulb: 30\n",
      "dozen: 36\n",
      "gram: 41\n",
      "loaf: 45\n",
      "handful: 54\n",
      "bag: 57\n",
      "jar: 58\n",
      "dash: 81\n",
      "ear: 111\n",
      "bottle: 117\n",
      "strip: 135\n",
      "fillet: 152\n",
      "pinch: 160\n",
      "quart: 172\n",
      "pint: 242\n",
      "package: 280\n",
      "stalk: 288\n",
      "stick: 328\n",
      "sprig: 454\n",
      "can: 464\n",
      "piece: 498\n",
      "head: 602\n",
      "bunch: 703\n",
      "clove: 822\n",
      "slice: 1041\n",
      "ounce: 3727\n",
      "teaspoon: 5433\n",
      "pound: 5934\n",
      "tablespoon: 8167\n",
      "cup: 20890\n",
      "na: 28676\n"
     ]
    }
   ],
   "source": [
    "# oh man some ingredients don't have a unit floof\n",
    "# we somehow need to deal with that so\n",
    "\n",
    "sortedIngredientsByUnit = dict()\n",
    "\n",
    "for ingredient in labeledIngredients:\n",
    "    # if there's a unit associated with the ingredient\n",
    "    if 'unit' in ingredient.keys():\n",
    "        unit = ingredient['unit']\n",
    "    else:\n",
    "        unit = 'na'\n",
    "        \n",
    "    # if that unit is already in the dictionary\n",
    "    if unit in sortedIngredientsByUnit.keys():\n",
    "        sortedIngredientsByUnit[unit].append(ingredient)\n",
    "    else:\n",
    "        # that unit is unseen, so we need to create it\n",
    "        sortedIngredientsByUnit[unit] = list(ingredient)\n",
    "\n",
    "unitQuantities = dict()\n",
    "for unit in sortedIngredientsByUnit.keys():\n",
    "    unitQuantities[unit] = len(sortedIngredientsByUnit[unit])\n",
    "\n",
    "for key, value in sorted(unitQuantities.iteritems(), key=lambda (k,v): (v,k)):\n",
    "    print \"%s: %s\" % (key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
