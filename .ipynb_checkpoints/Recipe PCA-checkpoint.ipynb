{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipes PCA\n",
    "### By Brian Kitano\n",
    "\n",
    "Okay, I'm going to use the Epicurious dataset to identify palates common across their recipes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction / Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure\n",
    "1. Download the JSON data\n",
    "2. Parse the JSON to extract recipe names and ingredients with their quantities.\n",
    "3. Create the data matrix M, where each column is a recipe and each row is an ingredient; the entry is the quantity in a normalized and standardized quantity (grams?)\n",
    "4. PCA\n",
    "\n",
    "Bonus: construct the bipartite graph of ingredients to recipes, and then project it down onto a unipartite graph of ingredients where the weight of each edge is the frequency of connections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Parse the ingredients to extract recipe names and ingredients with their quantities\n",
    "import json\n",
    "\n",
    "# load in the epicurious set\n",
    "with open('full_format_recipes.json') as f:\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    \n",
    "# print data[0]['ingredients']\n",
    "# len(data) = 20130\n",
    "\n",
    "# need to filter out the recipes that don't have ingredients listed\n",
    "# extractIngredients = lambda i: data[i].keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199315\n",
      "83465\n"
     ]
    }
   ],
   "source": [
    "def containsIngredients(index):\n",
    "    if 'ingredients' in data[i].keys():\n",
    "        return i\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# get all of the indices which contain ingredients\n",
    "cleanedIndices = [ containsIngredients(i) for i in range(len(data)) ]\n",
    "\n",
    "# get all of the ingredient lists as a list of lists\n",
    "cleanedIngredientsLists = [ data[i]['ingredients'] for i in cleanedIndices ]\n",
    "\n",
    "# flatten this list, which might contain duplicates\n",
    "cleanedIngredients = [ ingredient for ingredientList in cleanedIngredientsLists for ingredient in ingredientList]\n",
    "print len(cleanedIngredients)\n",
    "\n",
    "# remove any duplicates\n",
    "uniqueCleanedIngredients = list(set(cleanedIngredients))\n",
    "print len(uniqueCleanedIngredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "Before we write all of the ingredients to a file, we should do some NLP cleaning. In looking at the results of the first model run, it seems like to be conservative we should remove all the text that occurs in parentheses, as this seems to really mess up the CRF's ability to identify units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove things in parentheses (use regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83465\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# remove all the text that is inside a parenthesis\n",
    "noParenthesisIngredients = [re.sub(r'\\([^)]*\\)', '', ingredient) for ingredient in uniqueCleanedIngredients]\n",
    "\n",
    "print len(noParenthesisIngredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dealing with the word \"plus\"\n",
    "\n",
    "More complex problem. There are lots of ways that \"plus\" is used. Some examples:\n",
    "\n",
    "##### when quantities don't add nicely\n",
    "- \"1/2 cup plus 1 1/2 tablespoons red wine vinegar\"\n",
    "- \"1/2 cup plus 2 tablespoons granola\"\n",
    "- \"1/4 cup plus 1 tablespoon warm water\"\n",
    "- \"1/4 teaspoon plus 1/3 cup sugar\"\n",
    "- \"2 tablespoons plus 1/2 cup chopped fresh dill\"\n",
    "- \"1 tablespoon plus 1/2 teaspoon Dijon mustard\"\n",
    "- \"2/3 cup plus 6 tablespoons coarsely chopped pecans\"\n",
    "- \"1 cup plus 2 tablespoons whole milk\"\n",
    "- \"1 1/2 cups plus 2 tablespoons sugar\"\n",
    "- \"1 1/2 cups plus 2 tablespoons water\"\n",
    "- \"1 tablespoon plus 3/4 teaspoon ground cinnamon\"\n",
    "- \"1 tablespoon plus one teaspoon fresh lemon juice\"\n",
    "\n",
    "These are in a consistent format of UNIT QUANTITY PLUS UNIT QUANTITY INGREDIENT. If we add PLUS as a label, then over the 3k samples we have we might improve, but we might also tag some things as being PLUS when we don't want them to be.\n",
    "\n",
    "##### when there's a suggestion for more on the side (not a lot of errors there)\n",
    "- \"1/4 cup olive oil, plus more for grilling\"\n",
    "- \"5 teaspoons all-purpose flour plus more for dusting\"\n",
    "- \"2 tablespoons drained capers plus more for serving\"\n",
    "- \"1/2 cup freshly grated Parmesan cheese plus additional for passing\"\n",
    "- \"12 rice-paper rounds, plus more in case some tear\"\n",
    "- \"1 can whole tomatoes, plus juice\"\n",
    "- \"1 tablespoon chile oil containing sesame oil plus some of sediment from jar\"\n",
    "\n",
    "These ones seem like i can just remove all the words after the plus.\n",
    "\n",
    "##### other, stupid ones\n",
    "- \"8 cornichons, finely chopped, plus 2 pickled onions from the jar, minced\"\n",
    "- \"1/2 cup oil-packed sun-dried tomatoes, chopped, plus 2 tablespoons tomato oil\"\n",
    "- \"1 tablespoon fresh rosemary leaves or 1 teaspoon crumbled dried, plus rosemary sprigs for garnish\"\n",
    "- \"Juice of 1/4 lime, plus 1 lime wedge for garnish\"\n",
    "- \"1 1/2 cups sugar, plus 1/4 cup mixed with 1 tablespoon cinnamon, on a plate\"\n",
    "- \"1/2 fennel bulb, finely chopped, plus 1 tablespoon finely chopped fronds\"\n",
    "- \"1/4 cup chopped fresh cilantro plus 32 whole fresh cilantro leaves\"\n",
    "- \"6 large celery stalks, thickly sliced, plus 2 1/2 cups 1/2-inch-thick slices\"\n",
    "- \"6 fresh mint leaves plus 1 mint sprig for garnish\"\n",
    "\n",
    "So also there's like a utility function that might need to be taken into account: we really want our data to fit the format nicely of having a name, a unit, and a quantity. \n",
    "\n",
    "A really, really easy way to deal with all of this is just to get rid of all the \"plus\" ingredient listings, which are only ~3000 out of the 83k samples. It might mess up the data but it's easier. Also none of this is training or testing data, this is like actually \"I need this\" data so it's convenient if I just scrap the shitty stuff. It will also probably have come up in other sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80480"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use a regex to tag an igredient any time \"plus\" appears as a word with or without a comma on its own\n",
    "noPlusListings = list(filter(lambda ingredient: (re.search(\"\\s*(plus)\\,*\\s*\", ingredient) == None), noParenthesisIngredients))\n",
    "\n",
    "len(noPlusListings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dashes, commas, and other grammar thingies\n",
    "might be worth removing all of that, but not going to yet. \n",
    "\n",
    "##### Asterisks (*)\n",
    "Asterisks appear in two variants:\n",
    "\"2 1/2 pounds Jerusalem artichokes *\" where the asterisk is at the end, and \"*seedless red grapes\" where it's indicating that this is the start of a comment. We can thus remove anything after an asterisk, since it doesn't matter in either case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all the text after an asterisk\n",
    "asteriskFreeListings = [ re.sub(\"\\*.*\\n*\",'',ingredient) for ingredient in noPlusListings ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### typos\n",
    "\n",
    "like fam what how is that even ugh how do i check for typos here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"or\"\n",
    "we could remove all the tokens after the word \"or\", since it's optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the things after an or\n",
    "noOrListings = [ re.sub(\"[^A-z]\\.*\\,*\\s*(or|OR|Or)+.*\",'', ingredient) for ingredient in asteriskFreeListings ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's write this clean stuff to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the ingredients to a file, which we'll then feed to a model\n",
    "with open('ingredientsList.txt', 'a') as the_file:\n",
    "    for ingredient in noOrListings:\n",
    "        if ingredient != \"\":\n",
    "            asciiOnlyIngredient = \"\".join(i for i in ingredient if ord(i)<128)\n",
    "            ingredientString = asciiOnlyIngredient + \"\\n\"\n",
    "            the_file.write(ingredientString)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemon juice\n",
      "cup\n",
      "1 1/4\n"
     ]
    }
   ],
   "source": [
    "# okay, the model ran and i've got the sauce\n",
    "\n",
    "# load in the labeled stuff\n",
    "with open('results.json') as g:\n",
    "    labeledIngredients = json.load(g)\n",
    "    g.close()\n",
    "    \n",
    "print labeledIngredients[0]['name']\n",
    "print labeledIngredients[0]['unit']\n",
    "print labeledIngredients[0]['qty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "pound ounce\n",
      "bunch head\n",
      "fifth\n",
      "bunch\n",
      "cup\n",
      "stalk tablespoon\n",
      "clove clove\n",
      "jar\n",
      "tablespoon stalk\n",
      "teaspoon\n",
      "knob\n",
      "liter\n",
      "pound cup\n",
      "tablespoon cup\n",
      "pound fillet\n",
      "piece fillet\n",
      "pinch\n",
      "drop\n",
      "cup teaspoon\n",
      "teaspoon teaspoon\n",
      "bag\n",
      "gram\n",
      "pound pound\n",
      "steak\n",
      "rack\n",
      "square\n",
      "chunk\n",
      "cup cup\n",
      "packet\n",
      "teaspoon bag\n",
      "12-ounce\n",
      "teaspoon tablespoon\n",
      "cup cup tablespoon\n",
      "slice\n",
      "fillet\n",
      "can fillet\n",
      "slice slice\n",
      "handful\n",
      "stem\n",
      "quart\n",
      "tablespoon sprig\n",
      "12-ounce bottle\n",
      "pound stalk\n",
      "cup sprig\n",
      "box\n",
      "ounce ounce\n",
      "package\n",
      "12-ounce bag\n",
      "cup piece\n",
      "ounce\n",
      "sprig\n",
      "head\n",
      "loaf\n",
      "wedge\n",
      "cup tablespoon cup\n",
      "cup ounce\n",
      "strip\n",
      "pound slice\n",
      "cup cup cup\n",
      "bulb tablespoon\n",
      "sheet\n",
      "log\n",
      "splash\n",
      "tablespoon tablespoon\n",
      "ounce fillet\n",
      "envelope\n",
      "cup slice\n",
      "stick\n",
      "bulb\n",
      "ear\n",
      "twist\n",
      "bunch sprig\n",
      "batch\n",
      "tablespoon teaspoon\n",
      "stalk\n",
      "can\n",
      "ounce cup\n",
      "piece\n",
      "cup tablespoon\n",
      "pound\n",
      "ounce can\n",
      "dash\n",
      "head clove\n",
      "gallon\n",
      "dozen\n",
      "clove\n",
      "clove teaspoon\n",
      "branch\n",
      "pint\n",
      "cube\n",
      "ball\n",
      "tablespoon\n",
      "bunch bunch\n",
      "cup stalk\n",
      "pinch sprig\n",
      "pair\n",
      "segment\n",
      "ounce tablespoon\n",
      "cup strip\n",
      "12-ounce bunch\n",
      "fillet teaspoon\n",
      "ounce slice\n",
      "bottle\n"
     ]
    }
   ],
   "source": [
    "# now we need to normalize all of the units and measures. We'll use milliliters for volume and grams for mass.\n",
    "\n",
    "# first we'll get a list of all the units\n",
    "def containsUnit(i):\n",
    "    if 'unit' in labeledIngredients[i].keys():\n",
    "        return i\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# get all of the indices which contain units\n",
    "unitContainingIndices = [containsUnit(i) for i in range(len(labeledIngredients))]\n",
    "unitContainingIndices = list(set(unitContainingIndices))\n",
    "\n",
    "# get all of the units\n",
    "unitList = [labeledIngredients[i]['unit'] for i in list(set(unitContainingIndices))]\n",
    "\n",
    "# remove duplicates\n",
    "uniqueUnitList = list(set(unitList))\n",
    "\n",
    "print len(uniqueUnitList) # 764 bruh\n",
    "\n",
    "for unit in uniqueUnitList:\n",
    "    print unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre and Post Modeling Cleaning\n",
    "What cleaning should be done before we feed the model, and what cleaning should be done after? Also, should we change our factor functions? \n",
    "- \"5 flat anchovy filets\" the model reads with \"flat\" being the unit\n",
    "\n",
    "I can probably safely ignore where the unit is registered as not a real unit. In this case, I should create some sort of lookup for real units. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
